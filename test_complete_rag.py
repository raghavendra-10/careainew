#!/usr/bin/env python3
"""
Test complete RAG pipeline: Upload â†’ Retrieval â†’ LLM Answer
"""
import requests
import json
import time

def test_complete_rag_pipeline():
    """Test the full RAG pipeline"""
    base_url = "http://localhost:8002"
    
    print("ğŸ§ª Testing Complete RAG Pipeline...")
    print("=" * 50)
    
    # Test 1: Health check
    print("\n1. ğŸ“‹ Health Check")
    try:
        response = requests.get(f"{base_url}/health")
        print(f"âœ… Main API Status: {response.status_code}")
    except:
        print("âŒ Main API not responding")
        return
    
    # Test 2: Check LLM health
    print("\n2. ğŸ¤– LLM Health Check")
    try:
        from llm_integration import Qwen3LLMClient
        client = Qwen3LLMClient()
        health = client.health_check()
        if health["healthy"]:
            print("âœ… Qwen3 LLM is healthy")
        else:
            print(f"âš ï¸ Qwen3 LLM issue: {health.get('error', 'Unknown')}")
    except Exception as e:
        print(f"âŒ LLM health check failed: {e}")
    
    # Test 3: Simple search (without LLM)
    print("\n3. ğŸ” Testing Search (Retrieval Only)")
    search_data = {
        "query": "test document processing"
    }
    
    try:
        response = requests.post(
            f"{base_url}/api/v3/search",
            json=search_data,
            headers={"Content-Type": "application/json"}
        )
        print(f"Search Status: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            print(f"ğŸ“Š Found {result['total_results']} results")
            if result['results']:
                print(f"ğŸ“‹ Top result: {result['results'][0]['text'][:100]}...")
                print(f"ğŸ¯ Similarity: {result['results'][0]['similarity_score']:.3f}")
        else:
            print(f"âŒ Search failed: {response.text}")
    except Exception as e:
        print(f"âŒ Search test failed: {e}")
    
    # Test 4: Complete RAG Chat
    print("\n4. ğŸ’¬ Testing Complete RAG Chat")
    chat_data = {
        "query": "What is this document about?"
    }
    
    try:
        print("ğŸš€ Sending chat request...")
        response = requests.post(
            f"{base_url}/api/v3/chat",
            json=chat_data,
            headers={"Content-Type": "application/json"}
        )
        print(f"Chat Status: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            
            print(f"\nğŸ“ Query: {result['query']}")
            print(f"ğŸ¤– Answer: {result.get('answer', 'No answer generated')}")
            print(f"ğŸ“Š Sources: {result.get('sources', [])}")
            print(f"ğŸ”§ Pipeline: {result.get('pipeline', 'unknown')}")
            print(f"ğŸ§  Model: {result.get('llm_metadata', {}).get('model', 'unknown')}")
            print(f"ğŸ“‹ Search Results: {len(result.get('search_results', []))}")
            
            # Show context metadata
            ctx_meta = result.get('context_metadata', {})
            print(f"ğŸ“ˆ Avg Similarity: {ctx_meta.get('avg_similarity', 0):.3f}")
            print(f"ğŸ“„ Total Chunks: {ctx_meta.get('total_chunks', 0)}")
            
            if result.get('pipeline') == 'complete_rag':
                print("âœ… Complete RAG pipeline successful!")
            elif result.get('pipeline') == 'retrieval_only':
                print("âš ï¸ RAG pipeline partially successful (retrieval only)")
                print(f"LLM Error: {result.get('llm_error', 'Unknown')}")
            
        else:
            print(f"âŒ Chat failed: {response.text}")
            
    except Exception as e:
        print(f"âŒ Chat test failed: {e}")
    
    # Test 5: Different questions
    print("\n5. ğŸ¯ Testing Different Questions")
    test_questions = [
        "How does LlamaIndex process documents?",
        "What are the main sections in this document?",
        "Explain the chunking functionality"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n   Question {i}: {question}")
        try:
            response = requests.post(
                f"{base_url}/api/v3/chat",
                json={"query": question},
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get('answer', 'No answer')
                pipeline = result.get('pipeline', 'unknown')
                print(f"   Answer ({pipeline}): {answer[:150]}...")
            else:
                print(f"   âŒ Failed: {response.status_code}")
                
        except Exception as e:
            print(f"   âŒ Error: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ RAG Pipeline Test Complete!")

if __name__ == "__main__":
    test_complete_rag_pipeline()